{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excel table clustering using K-Means in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## To know:\n",
    "\n",
    "This code has been written by João Nuno Carvalho originally but some few adjustements have been made.\n",
    "(see https://github.com/joaocarvalhoopen/Excel_table_clustering_using_K-Means_ML for the original code)\n",
    "\n",
    "\n",
    "## How to:\n",
    "\n",
    "\n",
    "1) Define the table of data you wanna use in a excel worksheet knowing that the rows are what we want to cluster: in our case we want to use the dataset we generated before with *dataset_generation.py*. Save this excel file as a *.csv file.\n",
    "\n",
    "2) At the start menu select the Anaconda prompt and then go to the directory were you have your csv file and code file and start the Jupyter notebooks by making the command “jupyter notebook”. In the file list, double click on the code file to open it.\n",
    "\n",
    "3) In the program, change the name of the input file to your CSV file, change the different paths (working directory and dataset) and change the number of clusters that you want to generate.  \n",
    "\n",
    "4) Execute all the cells. It will generate a new CSV file, that terminates in “K_means”: at the end of each row you'll have the cluster ID corresponding.\n",
    "\n",
    "5) Now you can do all the analysis you want by for example opening the file in Excel and applying a filter on the new column data to see the elements of the separate clusters. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports.\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of clusters you want the algorithm to define\n",
    "num_clusters = 5\n",
    "# the name of the dataset in csv format\n",
    "filename = \"super_small_dataset_test.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# read the CSV file with the Pandas lib\n",
    "# path to the directory\n",
    "path_dir = \"/Users/justinesommerlatt/Documents/Defining-weather-scenarios/\"\n",
    "# path to your dataset\n",
    "dataframe = pd.read_csv(\"/Users/justinesommerlatt/Documents/Defining-weather-scenarios/super_small_dataset_test.csv\", encoding = \"cp1252\", sep = ';')\n",
    "df = dataframe.copy(deep=True)\n",
    "# df.head(5)[df.columns[0:4]]\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaces the NAN for 0.0 making something like hot encoding.\n",
    "    \n",
    "df = df.fillna(0.0)   # Fill the NAN (Not a Num)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# apply the K-Means Clustering algoritms\n",
    "# also possible to apply others clustering algorithms from scikit-learn to have comparisons\n",
    "# (see https://scikit-learn.org/stable/modules/classes.html#module-sklearn.cluster)\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=num_clusters, random_state=1)\n",
    "new = df._get_numeric_data()\n",
    "km.fit(new)\n",
    "predict=km.predict(new)\n",
    "df_kmeans = df.copy(deep=True)\n",
    "df_kmeans['Cluster KMeans'] = pd.Series(predict, index=df_kmeans.index)\n",
    "df_kmeans.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving to kmeans CSV file: gets the original data frame and adds to it one column in the end with the id of the corresponding cluster\n",
    "\n",
    "df_kmeans_orig = dataframe.copy(deep=True)\n",
    "df_kmeans_orig['Cluster KMeans'] = pd.Series(predict, index=df_kmeans.index)\n",
    "\n",
    "df_kmeans_orig = df_kmeans_orig.fillna(\"\")           # assigns df to a new dataframe\n",
    "\n",
    "filename_kmenas = filename[0:-4] + \"_kmeans_\" + str(num_clusters) + \".csv\"\n",
    "path_kmeans = path_dir + filename_kmenas\n",
    "df_kmeans_orig.to_csv(path_or_buf = path_kmeans, sep = \";\")\n",
    "print(\"The file has been generated!\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kmeans_orig.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the Elbow method for KMeans: it discovers in a \"scientific\" way the best number of cluster to specify to the KMeans algorithm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Ks = range(1, 25)\n",
    "km = [KMeans(n_clusters=i, random_state=1) for i in Ks]\n",
    "my_matrix = df._get_numeric_data()\n",
    "score = [km[i].fit(my_matrix).score(my_matrix) for i in range(len(km))]\n",
    "\n",
    "plt.plot(Ks, score)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
